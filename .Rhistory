x <- c("10", "2", "7", "89", "43", "1")
ii <- which(nchar(x) > 1)  ？
x <- c("10", "2", "7", "89", "43", "1")
ii <- which(nchar(x) > 1)
xs <- character(2 * length(x))
iis <- ii + 1:length(ii)
xs[iis] <- substr(x[ii], 2, 2)
xs[-iis] <- substr(x, 1, 1)
iis
x <- c("10", "2", "7", "89", "43", "1")
ii <- which(nchar(x) > 1)
xs <- rep('',length(ii)+length(x))
iis <- ii + 1:length(ii)
xs[iis] <- substr(x[ii], 2, 2)
xs[-iis] <- substr(x, 1, 1)
help("substr")
help('paste')
poem <- paste('I am a human')
pow= <- strsplit(poem,'')
pow= <- strsplit(poem,'')[[1]]
poem <- paste('I am a human')
pow <- strsplit(poem,'')
poem <- paste('I am a human')
pow <- strsplit(poem,'')[[1]]
b <- strsplit(poem,'')
help('strspliot')
help("strsplit")
n <- length(pow)
freq <- tabulate(nchar(pow))
nchar(pow)
help(tabulate)
options(repos=c("https://markbravington.github.io/Rmvb-repo",
getOption( "repos")))
install.packages("mvbutils")
install.packages("debug")
options(repos = unique( c(
mvb = 'https://markbravington.r-universe.dev',
getOption( 'repos')[ 'CRAN'])))
install.packages( "debug")
install.packages("mvbutils")
packageVersion('mvbutils')
install.packages("ggplot2")
install.packages("rjags")
install.packages("rmarkdown")
help('grep')
poem <- paste('I am a human')
pow <- strsplit(poem,'')[[1]]
n <- length(pow)
freq <- tabulate(nchar(pow))
ie <- grep("e",pow,fixed=TRUE) ## find ‘e’ words
n.e <- length(ie) ## number of ‘e’ words
ia <- grep("a",pow,fixed=TRUE) ## find ‘a’ words
iea <- ia[ia %in% ie] ## find words with ‘e’ and ‘a’
pow[iea] <- paste(pow[iea],"*",sep="")
poem <- paste('I am a human')
pow <- strsplit(poem,'')[[1]]
n <- length(pow)
freq <- tabulate(nchar(pow))
ie <- grep("e",pow,fixed=TRUE) ## find ‘e’ words
n.e <- length(ie) ## number of ‘e’ words
ia <- grep("a",pow,fixed=TRUE) ## find ‘a’ words
iea <- ia[ia %in% ie] ## find words with ‘e’ and ‘a’
pow[iea] <- paste(pow[iea],"*",sep="")
poem <- paste('I am a human, and you are also a human')
pow <- strsplit(poem,'')[[1]]
n <- length(pow)
freq <- tabulate(nchar(pow))
ie <- grep("e",pow,fixed=TRUE) ## find ‘e’ words
n.e <- length(ie) ## number of ‘e’ words
ia <- grep("a",pow,fixed=TRUE) ## find ‘a’ words
iea <- ia[ia %in% ie] ## find words with ‘e’ and ‘a’
pow[iea] <- paste(pow[iea],"*",sep="")
help('%in%')
1:10 %in% c(1,3,5,9)
ia %in% ie
poem <- paste("Inside me is a skeleton, of this I have no doubt,",
"now it’s got my flesh on, but it’s waiting to get out.")
pow <- strsplit(poem," ")[[1]] ## vector of poem words
req <- tabulate(nchar(pow))
ie <- grep("e",pow,fixed=TRUE) ## find ‘e’ words
n.e <- length(ie) ## number of ‘e’ words
ia <- grep("a",pow,fixed=TRUE) ## find ‘a’ words
iea <- ia[ia %in% ie] ## find words with ‘e’ and ‘a’
pow[iea] <- paste(pow[iea],"*",sep="")
poem <- paste("Inside me is a skeleton, of this I have no doubt,",
"now it’s got my flesh on, but it’s waiting to get out.")
pow <- strsplit(poem," ")[[1]] ## vector of poem words
n <- length(pow)
freq <- tabulate(nchar(pow))
ie <- grep("e",pow,fixed=TRUE) ## find ‘e’ words
n.e <- length(ie) ## number of ‘e’ words
ia <- grep("a",pow,fixed=TRUE) ## find ‘a’ words
iea <- ia[ia %in% ie] ## find words with ‘e’ and ‘a’
pow[iea] <- paste(pow[iea],"*",sep="")
poem <- paste('I am a human, and you are also a human')
pow1 <- strsplit(poem,'')[[1]]
poem <- paste('I am a human, and you are also a human')
pow1 <- strsplit(poem,'')[[1]]
n1 <- length(pow)
poem <- paste('I am a human, and you are also a human')
pow1 <- strsplit(poem,"")[[1]]
n1 <- length(pow)
poem <- paste("I am a human, and you are also a human")
pow1 <- strsplit(poem,"")[[1]]
n1 <- length(pow)
poem <- paste("I am a human, and you are also a human")
pow1 <- strsplit(poem,"")[[1]]
n1 <- length(pow)
poem <- paste("Inside me is a skeleton, of this I have no doubt,",
"now it’s got my flesh on, but it’s waiting to get out.")
pow <- strsplit(poem," ")[[1]] ## vector of poem words
n <- length(pow)
poem <- paste("I am a human, and you are also a human","what's fuck")
pow1 <- strsplit(poem,"")[[1]]
n1 <- length(pow)
poem <- paste("I am a human, and you are also a human","what's fuck")
pow1 <- strsplit(poem," ")[[1]]
n1 <- length(pow)
n1 <- length(pow1)
help('paste')
pow[iea]
paste(pow[iea],"*",sep="")
help('gsub')
poem <- paste("Inside me is a skeleton, of this I have no doubt,",
"now it’s got my flesh on, but it’s waiting to get out.")
pow <- strsplit(poem," ")[[1]] ## vector of poem words
n <- length(pow)
freq <- tabulate(nchar(pow))
ie <- grep("e",pow,fixed=TRUE) ## find ‘e’ words
n.e <- length(ie) ## number of ‘e’ words
ia <- grep("a",pow,fixed=TRUE) ## find ‘a’ words
iea <- ia[ia %in% ie] ## find words with ‘e’ and ‘a’
pow[iea] <- paste(pow[iea],"*",sep="")
poem <- paste("Inside me is a skeleton, of this I have no doubt,",
"now it’s got my flesh on, but it’s waiting to get out.")
p <- strsplit(poem,' ')[[1]]
n=tabulate(nchar(p))
poem <- paste("Inside me is a skeleton, of this I have no doubt,",
"now it’s got my flesh on, but it’s waiting to get out.")
p <- strsplit(poem,' ')[[1]]
n=tabulate(nchar(p))
help("gsub")
poem1 <- gsub(".","",gsub(",","",poem,fixed=TRUE),fixed=TRUE)
poem1
gusb(".","",poem)
gusb(".","",poem,fix=TRUE)
gsub(".","",poem)
poem <- paste("Inside me is a skeleton, of this I have no doubt,",
"now it’s got my flesh on, but it’s waiting to get out.")
w=gsub(".","",poem)
w=gsub(".","",poem,fix=TRUE)
w
mm<-gsub(".","/n" ,gsub(",","/n",poem,fixed=TRUE),fixed=TRUE)
mmm<-cat(gsub(".",".\n",gsub(", ",",\n",poem,fixed=TRUE),fixed=TRUE))
mm<-gsub(".","\n" ,gsub(",","\n",poem,fixed=TRUE),fixed=TRUE)
mm<-gsub(".",".\n" ,gsub(",",".\n",poem,fixed=TRUE),fixed=TRUE)
mm<-gsub(".","\n" ,gsub(",","\n",poem,fixed=TRUE),fixed=TRUE)
mmm<-cat(gsub(".",".\n",gsub(", ",",\n",poem,fixed=TRUE),fixed=TRUE))
mmm
mm
cat(gsub(".",".\n",gsub(", ",",\n",poem,fixed=TRUE),fixed=TRUE))
help('cat')
set.seed(0)
set.seed(0)
y <- rt(100,df=4)
help("hist")
hist(y)
m1=mean(y)
sd1=sd(y)
where(y-m1>2sd1)
y-m1>2sd1 or y-m1<2sd1
y-m1>2*sd1 or y-m1<*sd1
which(y-m1>2*sd1 or y-m1<*sd1)
y[y-m1>2*sd1 or y-m1<*sd1]
y[y-m1>2*sd1 & y-m1<*sd1]
y[y-m1>2*sd1 & y-m1<2*sd1]
yt<-y[y-m1>2*sd1 & y-m1<-2*sd1]
yt<- y[y-m1<2*sd1 & y-m1>-2*sd1]
set.seed(0);y <- rt(100,df=4) ##t分布，自由度
hist(y)
m1=mean(y)
sd1=sd(y)
yt<- y[y-m1<2*sd1 & y-m1>-2*sd1]
mean(yt)
library(gamair)
install.packages("gamair")
library(gamair)
data(hubble)
with(hubble,plot(x,y,xlab="Distance (Mpc)",ylab="Velocity (km/s)"))
hub.mod <- lm(y~x-1,data=hubble)
summary(hub.mod)
abline(a=0, b=hub.mod$coefficients)
##outliers
points(hubble$x[c(3,15)], hubble$y[c(3,15)], col="red", pch=16)
## omit possible outliers...
hub.mod1 <- lm(y~x-1,data=hubble[-c(3,15),])
summary(hub.mod1)
abline(a=0, b=hub.mod1$coefficients, col="red")
## convert Hubble const to age in years...
##1 megaparsec = 3.09e19 km
hubble.const <- c(coef(hub.mod),coef(hub.mod1))/3.09e19
age <- 1/hubble.const ## in seconds
(age/(60^2*24*365) )/1e9
## residuals...
plot(fitted(hub.mod),residuals(hub.mod),xlab="fitted values",
ylab="residuals")
plot(fitted(hub.mod1),residuals(hub.mod1),
xlab="fitted values",ylab="residuals")
##manually calculating standard deviation
sigmasq= 1/(length(hubble$x)-1) * sum((residuals(hub.mod))^2)
sqrt(sigmasq/sum((hubble$x)^2))
stde = sqrt(sigmasq/sum((hubble$x)^2))
##compared to:
summary(hub.mod)$coefficients
## Testing creationist hypothesis
cs.age = 6000 * (60^2*24 * 365)
cs.hubble = (1/cs.age)*3.09e19 ###roughly 163000000
##95% of the data within 2 sigma of mu
pnorm(2)-pnorm(-2)
##>99% of the data within 3 sigma of mu
pnorm(3)-pnorm(-3)
round(abs(coef(hub.mod)-cs.hubble)/stde)
# testing the Creationist hypothesis
t.stat<-abs(coef(hub.mod)-cs.hubble)/summary(hub.mod)$coefficients[2]
pt(-t.stat,df=length(hubble$x)-1)*2
## reproducing the t and p-values for beta=0
t0 = abs(coef(hub.mod))/summary(hub.mod)$coefficients[2]
p0 = pt(-t0,df=length(hubble$x)-1)*2
t0
p0
summary(hub.mod)$coefficients
# Confidence interval
q = qt(0.025, df = length(hubble$x)-1)
sigb <- summary(hub.mod1)$coefficients[2]
h.ci <- coef(hub.mod)+c(q,-q)*sigb
h.ci ## Hubble CI
h.ci <- h.ci*60^2*24*365.25/3.09e19 # convert to 1/years
sort(1/h.ci)/1e9 #billions of years
help hubble
data(hubble)
View(hub.mod1)
View(hubble)
source("~/Library/CloudStorage/OneDrive-个人/第一学期/GENERIALISED REGRESSION/hubble.R")
abline(a=0, b=hub.mod$coefficients)
summary(hub.mod)$coefficients
pnorm
pnorm(2)-pnorm(-2)
round(abs(coef(hub.mod)-cs.hubble)/stde)
summary(hub.mod)$coefficients[2]
hub.mod$coefficients[2]
View(hub.mod)
summary(hub.mod)
pt(-t0,df=length(hubble$x)-1)*2
help pt
help('pt')
poem <- paste("I am a human, and you are also a human","what's fuck")
pow1 <- strsplit(poem," ")[[1]]
strsplit(poem," ")
strsplit(poem," ")[[1]]
poem <- paste("I am a human, and you are also a human","what's fuck")
pow1 <- strsplit(poem," ")[[1]]
a <- strsplit(poem," ")
help('strsplit')
typeof(a)
typeof(pow1)
poem <- paste("I am a human, and you are also a human","what's fuck")
pow1 <- strsplit(poem," ")[[1]][1]
pow1 <- strsplit(poem," ")[[1]][1]
pow1
list(("1,2,3","1"),("1","10"))
my_list <- list(c("1", "2", "3", "1"), c("1", "10"))
list(c("1", "2", "3", "1"), c("1", "10"))
my_list <- list(c("1", "2"), c("1", "10"))
list(c("1", "2"), c("1", "10"))
#Practical 1: A Markov Ulysses
#basic model: pth-order Markov model
#advantage1: search for in common words(m) instead of all words(n)
#advantage2: not m**p array if it's p-nd order, but (n-p)*(p+1) array
#advantage3: store tokens (indices in m) instead of actual words
setwd("/Users/jingwenjiang/Documents/Practical-1-A-Markov-Ulysses")
# 3 prepare for data
a <- scan("4300-0.txt",what="character",skip=73,nlines=32858-73,
fileEncoding="UTF-8")
a <- gsub("_(","",a,fixed=TRUE) ## remove "_("
# 4 treat punctuation just like words
split_punct <- function(text1,punc) {
pp<-grep(punc,text1,fixed=TRUE)
if (length(pp)==0){
return(text1)
}
text2<-character(length(text1)+length(pp))
pps<-pp+1:length(pp)
text2[pps]<-punc
dd<-gsub(punc,'',text1,fixed=TRUE)
text2[-pps]<-dd
return(text2)
}
t<-c('i','am','human.','am','i?') ##example
w<-split_punct(t,'?')
# 5 treated text
s<-a
for (i in c(',','.',';','!',':','?')){
s<-split_punct(s,i)
}
text<-s
# 6 acquire common-word set
ttext<-tolower(text)
# (a)
uu <-unique(ttext) #32794
# (b)
ii<-match (ttext,uu) #309129
# (c)
tt<-tabulate(ii)
dd<-data.frame(word=uu,count=tt)
# (d)
dd_sort<-sort(dd$count,decreasing = TRUE)
threshold<-dd_sort[1000]
m<- length(which(dd$count>=threshold)) #1005
# (e)
common_words_indices<-which(dd$count>=threshold)
b <- dd$word[common_words_indices]
View(b)
b
#4
split_punct<-function(text,punct){
ip<-grep(punct,text,fixed=TRUE)                ##get index of the word with punctuation
new_text<-rep("",length(ip)+length(text))      ##create a new vector to hold the new text
changedindex<-ip+1:length(ip)                  ##compute the index number of the place which punctuation should be at
new_text[changedindex]<-punct                  ##put the punctuation to the new place
new_text[-changedindex]<-gsub(punct,"",text,fixed=TRUE) ##replace the original punctuation with ""
new_text
}
comma=split_punct(a,",")                         ##an example to test the function
#5
a_sep=a
a_sep=split_punct(a_sep,",")                     ##remove ","
a_sep=split_punct(a_sep,".")                     ##remove "."
a_sep=split_punct(a_sep,";")                     ##remove ";"
a_sep=split_punct(a_sep,"!")                     ##remove "!"
a_sep=split_punct(a_sep,":")                     ##remove ":"
a_sep=split_punct(a_sep,"?")                     ##remove "?"
#6
#a
a_low<-tolower(a_sep)
#a_new<-gsub("—","",a_low,fixed=TRUE)            ## remove "-"
#a_new<-gsub("_","",a_new,fixed=TRUE)            ## remove "_"
#a_new<-gsub("(","",a_new,fixed=TRUE)            ## remove "("
#a_new<-gsub(")","",a_new,fixed=TRUE)            ## remove ")"
##??? ip<-grep("[,\\.;!:?]",a_low,fixed=TRUE) 为什么不行
ip1<-grep(",",a_low,fixed=TRUE)
ip2<-grep(".",a_low,fixed=TRUE)
ip3<-grep(";",a_low,fixed=TRUE)
ip4<-grep("!",a_low,fixed=TRUE)
ip5<-grep(":",a_low,fixed=TRUE)
ip6<-grep("?",a_low,fixed=TRUE)
index<-c(ip1,ip2,ip3,ip4,ip5,ip6)
a_uni<-unique(a_low)
#b
a_index<-match(a_low[-index],a_uni)    ## the index of the original word in the unique vector
a_index
#c
freq<-tabulate(a_index)
freq
#d
M<-1000
des_index<-order(freq,decreasing=TRUE)
M_index<-des_index[1:M]
#e
b1<-a_low[-index][M_index]
b1
b==b1
setwd("/Users/jingwenjiang/Documents/Practical-1-A-Markov-Ulysses")
# 3 prepare for data
a <- scan("4300-0.txt",what="character",skip=73,nlines=32858-73,
fileEncoding="UTF-8")
a <- gsub("_(","",a,fixed=TRUE) ## remove "_("
# 4 treat punctuation just like words
split_punct <- function(text1,punc) {
pp<-grep(punc,text1,fixed=TRUE)
if (length(pp)==0){
return(text1)
}
text2<-character(length(text1)+length(pp))
pps<-pp+1:length(pp)
text2[pps]<-punc
dd<-gsub(punc,'',text1,fixed=TRUE)
text2[-pps]<-dd
return(text2)
}
t<-c('i','am','human.','am','i?') ##example
w<-split_punct(t,'?')
# 5 treated text
s<-a
for (i in c(',','.',';','!',':','?')){
s<-split_punct(s,i)
}
text<-s
# 6 acquire common-word set
ttext<-tolower(text)
# (a)
uu <-unique(ttext) #32794
# (b)
ii<-match (ttext,uu) #309129
# (c)
tt<-tabulate(ii)
dd<-data.frame(word=uu,count=tt)
# (d)
dd_sort<-sort(dd$count,decreasing = TRUE)
threshold<-dd_sort[1000]
m<- length(which(dd$count>=threshold)) #1005
# (e)
common_words_indices<-which(dd$count>=threshold)
b <- dd$word[common_words_indices]
b
grep(".", a)
length(grep(".", a))
grep('buck',a)
